# シミュレーション回数確保のメモ

[リポジトリへのリンク](https://github.com/r-koike/eagent)

## 概要
TNNLSの論文の"V. Simulation Experiments"の"C. Comparison of Proposed Methods"において、各提案手法の性能を比較している。
ここに掲載するためのシミュレーションを回す方法を記述する。

2022年7月4日現在は
- 2つのタスク
- 5つの手法
で、それぞれ5回ずつ試している。

以下、特に断りが無ければカレントディレクトリはリポジトリのルート（install.md等がある場所）とする。

## プライベートリポジトリのセットアップ(スキップ可)
複数台のPCで学習してログを共有するなら、[元のパブリックディレクトリ](https://github.com/r-koike/eagent)とは別のプライベートリポジトリを作成し、そちら側で管理すると楽。
- [git remote originの変更方法](https://qiita.com/minoringo/items/917e325892733e0d606e)

## 環境セットアップ
[install.md](install.md)を参照してセットアップする。
以下のコマンドで学習が開始することを確認する。
しばらく待って、`log`ディレクトリの中にログが出力されることを確認する。
確認したら、`Ctrl+C`で停止して、`log`ディレクトリに作成されたログは一旦削除する。
```bash
python train.py -c ewalker_iso6.json
```

## スクリプトファイルの準備(スキップしてコマンド直打ちでも可)
`scripts`ディレクトリを作成し、Ubuntuなら`scripts/train.sh`ファイル、Windows(PowerShell)なら`scripts/train.ps1`ファイルを作成する。
その内容は以下の通り。
```bash
python ./train.py -c [configファイル名]
# 以下、実行したい学習を実行したい回数だけ記述する。
```

configファイル名については後述。
例えば、歩行タスクを5つ全ての手法で1回ずつ学習したいなら以下のように記述する。
```bash
python ./train.py -c ewalker_dec.json
python ./train.py -c ewalker_iso6.json
python ./train.py -c ewalker_rand.json
python ./train.py -c ewalker_f.json
python ./train.py -c ewalker_ff.json
```

マニピュレーションタスクを5つ全ての手法で1回ずつ学習したいなら以下のように記述する。
```bash
python ./train.py -c ehand_egg_dec.json
python ./train.py -c ehand_egg_iso6.json
python ./train.py -c ehand_egg_rand.json
python ./train.py -c ehand_egg_f.json
python ./train.py -c ehand_egg_ff.json
```

#### configファイル名
[configsフォルダ](eagent/configs/)
の中にあるdefault.json**以外**のファイル名と対応している。
論文中の図との対応は以下の通り。
- (ファイル名) -> (論文中の名前)
- `ewalker_dec.json` -> `MDM-Ant40`
- `ewalker_iso6.json` -> `ICM-Starfish6` (72スレッドが立つので高負荷)
- `ewalker_rand.json` -> `RAND-Starfish6`
- `ewalker_f.json` -> `F-Starfish6`
- `ewalker_ff.json` -> `FF-Starfish6`

- `ehand_egg_dec.json` -> `MDM-Hand24`
- `ehand_egg_iso6.json` -> `ICM-Hand5` (72スレッドが立つので高負荷)
- `ehand_egg_rand.json` -> `RAND-Hand5`
- `ehand_egg_f.json` -> `F-Hand5`
- `ehand_egg_ff.json` -> `FF-Hand5`

(参考)36コアのWindows PCなら、
- `ICM`を1つだけ回す
- 他の何かを2つ同時に回す
のいずれかをやると、CPU使用率がちょうど100%程度になり、効率的に学習できた。

## 学習実行
Ubuntuなら`./scripts/train.sh`で、PowerShellなら`./scripts/train.ps1`で、リポジトリのルートから実行する。
ログ、つまり学習結果が`log`ディレクトリに保存されていく。

PowerShellで実行ポリシー関連のエラーが出たら、管理者権限のPowerShellで`Set-ExecutionPolicy Remotesigned`をして、PowerShellを再度開き、スクリプトを実行する。

## 学習を中断&再開する(スキップ可)
#### 中断
`eagent/configs/`の中のjsonファイルにおいて、`"checkpoint_cycle": [世代数],`という設定項目がある。
ここに記述された`[世代数]`が経過するごとに、学習の復帰可能なチェックポイントがログディレクトリに作成される。
ただし、**checkpoint_cycleはsave_parameter_cycleの倍数に設定すること**。
復帰に必要なファイルの一覧表は、ログディレクトリへ同時に作成される`checkpoint.json`に記述してある。
それらが保存されていたら、Ctrl+Cで中断できる。

#### 復帰
チェックポイントは、恐らくCPUのアーキテクチャ等が変わると読み込めなくなります。
そのため、**チェックポイントはそれを作成したPCでのみ利用することが無難です**。
```bash
# 学習に復帰するコマンド
python ./train.py -c [学習を開始した際のコンフィグファイル名] -o `[ログディレクトリ名]`

# 例えば、`python ./train.py -c ewalker_dec.json`で学習を開始し、
# ログが`log/0.8.8_20220401_080808`に保存された場合は、以下のコマンドで学習を再開できる。
python ./train.py -c ewalker_dec.json -o `log/0.8.8_20220401_080808`
```

## 学習結果をグラフで確認(スキップ可)
`plot_history.ipynb`の一番下のセルのsimnameを、結果確認したいディレクトリ名に変更する。
セルを上から順番に全部実行することで、学習結果を確認できる。
学習中でも問題ない。

Jupyter notebookの実行環境が無いなら、`.py`ファイルを作成して全てをコピーして実行することでも代用可能であるはず。

## 学習結果を動画で確認(スキップ可)
`python demo.py -s 1 -i log/[ディレクトリ名]/parameter_best.json`を実行する。
学習中でも問題ないと思うが、学習中はやめておいたほうが無難。

## ログの整理
ログのディレクトリが例えば`0.8.8_20220401_080808`とする。
学習に問題が無さそうだったら、`log/old/0.8.8_20220401_080808`へディレクトリごと移動する。
その後、`log/catalog.json`に例に倣って追記する。
